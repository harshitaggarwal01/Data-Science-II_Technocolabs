{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from adabound import AdaBound\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   emotion  35887 non-null  int64 \n",
      " 1   pixels   35887 non-null  object\n",
      " 2   Usage    35887 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,train_y,X_test,test_y=[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "           X_train.append(np.array(val,'float32'))\n",
    "           train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "           X_test.append(np.array(val,'float32'))\n",
    "           test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 100\n",
    "epochs = 50\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cannot produce\n",
    "#normalizing data between oand 1\n",
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##designing the cnn\n",
    "#1st convolution layer\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# #4th convolution layer\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# # model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_labels, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 44, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 20, 20, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 5, 5, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 2,025,607\n",
      "Trainable params: 2,025,607\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harshit\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harshit\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Compliling the model\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=AdaBound(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Harshit\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Harshit\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harshit\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Harshit\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harshit\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harshit\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Harshit\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "28709/28709 [==============================] - 25s 863us/step - loss: 1.7838 - acc: 0.2559 - val_loss: 1.7306 - val_acc: 0.2898\n",
      "Epoch 2/50\n",
      "28709/28709 [==============================] - 20s 694us/step - loss: 1.6569 - acc: 0.3383 - val_loss: 1.5689 - val_acc: 0.3828\n",
      "Epoch 3/50\n",
      "28709/28709 [==============================] - 19s 650us/step - loss: 1.5426 - acc: 0.3909 - val_loss: 1.4464 - val_acc: 0.4480\n",
      "Epoch 4/50\n",
      "28709/28709 [==============================] - 18s 642us/step - loss: 1.4576 - acc: 0.4299 - val_loss: 1.3815 - val_acc: 0.4620TA: 0s - loss: 1.4591\n",
      "Epoch 5/50\n",
      "28709/28709 [==============================] - 18s 640us/step - loss: 1.4051 - acc: 0.4559 - val_loss: 1.3361 - val_acc: 0.4826\n",
      "Epoch 6/50\n",
      "28709/28709 [==============================] - 18s 634us/step - loss: 1.3562 - acc: 0.4793 - val_loss: 1.3139 - val_acc: 0.4957\n",
      "Epoch 7/50\n",
      "28709/28709 [==============================] - 18s 627us/step - loss: 1.3263 - acc: 0.4913 - val_loss: 1.2806 - val_acc: 0.5096\n",
      "Epoch 8/50\n",
      "28709/28709 [==============================] - 18s 637us/step - loss: 1.2873 - acc: 0.5086 - val_loss: 1.2897 - val_acc: 0.5071\n",
      "Epoch 9/50\n",
      "28709/28709 [==============================] - 18s 641us/step - loss: 1.2636 - acc: 0.5160 - val_loss: 1.2265 - val_acc: 0.5325: 1.2658 - a - ETA: 9s - loss: 1.2675 - acc: - ETA: 8s - loss: 1.2708 - acc: 0.51 - ETA: 8s - loss: 1.2714 - acc: 0.51 - ETA: 8s - loss: 1.2710 - acc: 0.512 - ETA: 8s - loss: 1.2708 - acc: - ETA: 7s - loss: 1.2714 - acc: 0.51 - ETA: 7s - loss: 1.2711 - acc: 0. - ETA: 7s - loss: 1.2715 - acc: 0. - ETA: 7s - lo - ETA: 3s - loss: 1.2700 - acc: 0.5 - ETA: 3s - loss: 1.2690 - acc: 0.515 - ETA: 3s - loss: - ETA: 1s\n",
      "Epoch 10/50\n",
      "28709/28709 [==============================] - 18s 641us/step - loss: 1.2343 - acc: 0.5258 - val_loss: 1.2245 - val_acc: 0.5291s: 1.2297 - acc: 0.52 - ETA: 3s  - ETA: 1s - loss\n",
      "Epoch 11/50\n",
      "28709/28709 [==============================] - 17s 600us/step - loss: 1.2102 - acc: 0.5378 - val_loss: 1.2014 - val_acc: 0.5417\n",
      "Epoch 12/50\n",
      "28709/28709 [==============================] - 18s 639us/step - loss: 1.1877 - acc: 0.5459 - val_loss: 1.1900 - val_acc: 0.5548- loss: 1.1896 - ac - ETA: 1s - loss: 1. - ETA: 0s - loss: 1.1880 - a - ETA: 0s - loss: 1.1888 - acc: 0\n",
      "Epoch 13/50\n",
      "28709/28709 [==============================] - 19s 645us/step - loss: 1.1673 - acc: 0.5559 - val_loss: 1.1639 - val_acc: 0.5564- loss: 1.1611 - acc: 0.5 - ETA: 7s - - ETA: 5s - loss: 1.1608 - acc - ETA: 5s - loss: 1.1643 - acc: 0. - ETA: 5s - loss: 1.1654 - acc - ETA: 4s - loss: 1.1668 - acc:  - ETA: 4s - loss: 1.1667 - - ETA: 0s - loss: 1.16\n",
      "Epoch 14/50\n",
      "28709/28709 [==============================] - 17s 606us/step - loss: 1.1527 - acc: 0.5625 - val_loss: 1.1699 - val_acc: 0.5483\n",
      "Epoch 15/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 1.1349 - acc: 0.5690 - val_loss: 1.1701 - val_acc: 0.5556\n",
      "Epoch 16/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 1.1196 - acc: 0.5742 - val_loss: 1.1557 - val_acc: 0.5623\n",
      "Epoch 17/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 1.1005 - acc: 0.5814 - val_loss: 1.1529 - val_acc: 0.5584\n",
      "Epoch 18/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 1.0910 - acc: 0.5872 - val_loss: 1.1281 - val_acc: 0.5720\n",
      "Epoch 19/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 1.0702 - acc: 0.5942 - val_loss: 1.1228 - val_acc: 0.5804\n",
      "Epoch 20/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 1.0535 - acc: 0.5971 - val_loss: 1.1419 - val_acc: 0.5676\n",
      "Epoch 21/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 1.0375 - acc: 0.6066 - val_loss: 1.1007 - val_acc: 0.5874\n",
      "Epoch 22/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 1.0246 - acc: 0.6111 - val_loss: 1.1035 - val_acc: 0.5798\n",
      "Epoch 23/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 1.0091 - acc: 0.6140 - val_loss: 1.1062 - val_acc: 0.5862\n",
      "Epoch 24/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 0.9915 - acc: 0.6240 - val_loss: 1.0999 - val_acc: 0.5890\n",
      "Epoch 25/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 0.9814 - acc: 0.6258 - val_loss: 1.0936 - val_acc: 0.5952\n",
      "Epoch 26/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 0.9700 - acc: 0.6301 - val_loss: 1.0961 - val_acc: 0.5988\n",
      "Epoch 27/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 0.9500 - acc: 0.6404 - val_loss: 1.0997 - val_acc: 0.5926\n",
      "Epoch 28/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 0.9377 - acc: 0.6422 - val_loss: 1.0951 - val_acc: 0.5879\n",
      "Epoch 29/50\n",
      "28709/28709 [==============================] - 17s 583us/step - loss: 0.9262 - acc: 0.6467 - val_loss: 1.0918 - val_acc: 0.5974\n",
      "Epoch 30/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 0.9142 - acc: 0.6527 - val_loss: 1.0772 - val_acc: 0.5943\n",
      "Epoch 31/50\n",
      "28709/28709 [==============================] - 17s 578us/step - loss: 0.8972 - acc: 0.6597 - val_loss: 1.1117 - val_acc: 0.5940\n",
      "Epoch 32/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 0.8850 - acc: 0.6628 - val_loss: 1.1397 - val_acc: 0.5871\n",
      "Epoch 33/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 0.8701 - acc: 0.6730 - val_loss: 1.1484 - val_acc: 0.5963\n",
      "Epoch 34/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 0.8597 - acc: 0.6768 - val_loss: 1.1145 - val_acc: 0.5935\n",
      "Epoch 35/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 0.8383 - acc: 0.6831 - val_loss: 1.1322 - val_acc: 0.6007\n",
      "Epoch 36/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 0.8292 - acc: 0.6893 - val_loss: 1.1224 - val_acc: 0.5935\n",
      "Epoch 37/50\n",
      "28709/28709 [==============================] - 17s 582us/step - loss: 0.8202 - acc: 0.6909 - val_loss: 1.1360 - val_acc: 0.6018\n",
      "Epoch 38/50\n",
      "28709/28709 [==============================] - 17s 583us/step - loss: 0.8050 - acc: 0.6941 - val_loss: 1.1194 - val_acc: 0.5932\n",
      "Epoch 39/50\n",
      "28709/28709 [==============================] - 17s 583us/step - loss: 0.7912 - acc: 0.6996 - val_loss: 1.1620 - val_acc: 0.5929\n",
      "Epoch 40/50\n",
      "28709/28709 [==============================] - 17s 583us/step - loss: 0.7809 - acc: 0.7027 - val_loss: 1.1439 - val_acc: 0.6027\n",
      "Epoch 41/50\n",
      "28709/28709 [==============================] - 17s 582us/step - loss: 0.7710 - acc: 0.7101 - val_loss: 1.1530 - val_acc: 0.6024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 0.7522 - acc: 0.7136 - val_loss: 1.1635 - val_acc: 0.5965\n",
      "Epoch 43/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 0.7423 - acc: 0.7206 - val_loss: 1.1614 - val_acc: 0.5974\n",
      "Epoch 44/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 0.7285 - acc: 0.7267 - val_loss: 1.1595 - val_acc: 0.6013\n",
      "Epoch 45/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 0.7231 - acc: 0.7290 - val_loss: 1.1762 - val_acc: 0.5896\n",
      "Epoch 46/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 0.7112 - acc: 0.7321 - val_loss: 1.1749 - val_acc: 0.5954\n",
      "Epoch 47/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 0.7007 - acc: 0.7342 - val_loss: 1.1897 - val_acc: 0.5952\n",
      "Epoch 48/50\n",
      "28709/28709 [==============================] - 17s 579us/step - loss: 0.6820 - acc: 0.7420 - val_loss: 1.1902 - val_acc: 0.6066\n",
      "Epoch 49/50\n",
      "28709/28709 [==============================] - 17s 580us/step - loss: 0.6616 - acc: 0.7522 - val_loss: 1.1866 - val_acc: 0.5988\n",
      "Epoch 50/50\n",
      "28709/28709 [==============================] - 17s 581us/step - loss: 0.6561 - acc: 0.7533 - val_loss: 1.2270 - val_acc: 0.6010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c46e938948>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the  model to  use it later on\n",
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.metrics.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
